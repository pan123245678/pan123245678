# Linux内核崩溃堆栈生成与调试完全指南

## 1. **内核崩溃类型与堆栈获取方式**

### **内核崩溃类型**
| 类型 | 触发机制 | 堆栈获取方式 |
|------|----------|--------------|
| **Oops** | 非致命错误，内核继续运行 | 控制台/dmesg |
| **Panic** | 致命错误，内核停止 | 控制台/dmesg + 可能kdump |
| **硬件异常** | CPU异常、内存错误等 | kdump + 特殊寄存器 |
| **软死锁** | 死锁检测触发 | hung_task + watchdog |

## 2. **Oops信息生成与分析**

### **2.1 触发Oops**
```c
// 示例：触发空指针解引用Oops
#include <linux/module.h>
#include <linux/kernel.h>

static int __init oops_init(void)
{
    printk(KERN_INFO "Loading oops module\n");
    
    // 方法1：空指针解引用
    *(int *)0 = 0;
    
    // 方法2：使用BUG()
    // BUG();
    
    // 方法3：使用BUG_ON(condition)
    // BUG_ON(1 == 1);
    
    return 0;
}

static void __exit oops_exit(void)
{
    printk(KERN_INFO "Unloading oops module\n");
}

module_init(oops_init);
module_exit(oops_exit);
MODULE_LICENSE("GPL");
```

### **2.2 解析Oops信息**
```
[ 1234.567890] Unable to handle kernel NULL pointer dereference at virtual address 00000000
[ 1234.567900] pgd = c0004000
[ 1234.567910] [00000000] *pgd=00000000
[ 1234.567920] Internal error: Oops: 805 [#1] PREEMPT SMP ARM
[ 1234.567930] Modules linked in: oops_module(PO+) ...
[ 1234.567940] CPU: 0 PID: 1234 Comm: insmod Tainted: P        W  O    4.19.0
[ 1234.567950] Hardware name: XXX
[ 1234.567960] PC is at oops_init+0x14/0x20 [oops_module]
[ 1234.567970] LR is at do_one_initcall+0x50/0x1c0
[ 1234.567980] pc : [<bf000014>]    lr : [<c0100150>]    psr: 60000013
[ 1234.567990] sp : df83fe50  ip : 00000000  fp : 00000000
[ 1234.568000] r10: 00000000  r9 : c0d5d4c0  r8 : bf000000
[ 1234.568010] r7 : 00000000  r6 : c0d5d540  r5 : bf000080  r4 : 00000000
[ 1234.568020] r3 : 00000000  r2 : 00000000  r1 : 00000000  r0 : bf000080
[ 1234.568030] Flags: nZCv  IRQs on  FIQs on  Mode SVC_32  ISA ARM  Segment user
[ 1234.568040] Control: 10c5387d  Table: 5f5f0040  DAC: 00000015
[ 1234.568050] Process insmod (pid: 1234, stack limit = 0xdf83e210)
[ 1234.568060] Stack: (0xdf83fe50 to 0xdf840000)
[ 1234.568070] fe40:                                      bf000000 00000000 c0110a94 00000000
[ 1234.568080] fe60: c0d5d540 bf000080 00000000 c0d5d4c0 df83fe9c df83fe80 c0100150 bf000014
[ 1234.568090] fe80: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
[ 1234.568100] fea0: df83feb4 df83fea0 c0107c40 c0100140 00000000 00000000 00000000 00000000
[ 1234.568110] fec0: df83ff14 df83fed0 c0132e64 c0107c28 bf000000 bf000080 00000000 00000000
[ 1234.568120] fee0: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
[ 1234.568130] ff00: 00000000 00000000 00000000 00000000 00000000 00000000 df83ff4c df83ff18
[ 1234.568140] ff20: c0133170 c0132dd0 00000000 00000000 bf000000 00000000 df83ff7c df83ff50
[ 1234.568150] ff40: c0101a64 c013314c 00000000 00000000 00000000 00000000 00000000 00000000
[ 1234.568160] ff60: 00000000 00000000 00000000 00000000 00000000 00000000 df83ffa4 df83ff80
[ 1234.568170] ff80: c0008ae4 c01019e8 00000000 00000000 00000000 00000000 00000000 00000000
[ 1234.568180] ffa0: 00000000 df83ffb0 c0008940 c0008a7c 00000000 00000000 00000000 00000000
[ 1234.568190] ffc0: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
[ 1234.568200] ffe0: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
[ 1234.568210] Code: e24cb004 e92d4000 e1a04000 ebfe34bc (e5843000) 
[ 1234.568220] ---[ end trace 1234567890abcdef ]---
```

## 3. **kdump机制配置与使用**

### **3.1 kdump原理**
```
正常内核（第1个内核）
    ↓ 崩溃
触发kdump
    ↓
加载捕获内核（第2个内核）
    ↓
保存崩溃内存镜像（vmcore）
    ↓
分析vmcore
```

### **3.2 kdump安装配置**

#### **Ubuntu/Debian**
```bash
# 安装kdump工具
sudo apt-get update
sudo apt-get install kdump-tools crash kexec-tools

# 配置grub
sudo nano /etc/default/grub
# 添加：
GRUB_CMDLINE_LINUX_DEFAULT="crashkernel=384M"
# 或更精确的设置：
GRUB_CMDLINE_LINUX_DEFAULT="crashkernel=384M-:128M"

# 更新grub
sudo update-grub

# 配置kdump
sudo nano /etc/default/kdump-tools
# 设置：
USE_KDUMP=1
# KDUMP_COREDIR="/var/crash"
```

#### **CentOS/RHEL/Fedora**
```bash
# 安装工具
sudo yum install kexec-tools crash
# 或
sudo dnf install kexec-tools crash

# 配置kdump内存
sudo grubby --update-kernel=ALL --args="crashkernel=512M"

# 启用服务
sudo systemctl enable kdump.service
sudo systemctl start kdump.service
```

### **3.3 验证kdump配置**
```bash
# 检查内核参数
cat /proc/cmdline | grep crashkernel

# 检查kdump状态
sudo kdumpctl status
sudo systemctl status kdump

# 检查保留内存
cat /sys/kernel/kexec_crash_size
cat /proc/iomem | grep -i crash

# 测试kdump（触发panic）
echo c | sudo tee /proc/sysrq-trigger
# 或
sudo sysrq c
```

## 4. **手动触发内核崩溃获取堆栈**

### **4.1 使用SysRq键**
```bash
# 启用SysRq
echo 1 > /proc/sys/kernel/sysrq

# 触发紧急同步
echo s > /proc/sysrq-trigger

# 触发重新挂载为只读
echo u > /proc/sysrq-trigger

# 触发panic（强制崩溃）
echo c > /proc/sysrq-trigger

# 一次性启用所有SysRq功能
echo 1 > /proc/sys/kernel/sysrq
echo c > /proc/sysrq-trigger
```

### **4.2 内核模块触发**
```c
// panic_module.c - 触发内核panic
#include <linux/module.h>
#include <linux/kernel.h>
#include <linux/panic.h>

static int __init panic_init(void)
{
    printk(KERN_INFO "Triggering kernel panic...\n");
    
    // 方法1：直接panic
    panic("Test panic from module");
    
    // 方法2：通过BUG()
    // BUG();
    
    // 方法3：除零错误
    // int a = 1 / 0;
    
    return 0;
}

static void __exit panic_exit(void)
{
    printk(KERN_INFO "Module unloaded (if panic didn't happen)\n");
}

module_init(panic_init);
module_exit(panic_exit);
MODULE_LICENSE("GPL");
```

### **4.3 通过/proc文件系统**
```bash
# 触发soft lockup检测（需要配置）
echo 1 > /proc/sys/kernel/softlockup_panic

# 触发hard lockup检测
echo 1 > /proc/sys/kernel/nmi_watchdog

# 触发hung task检测
echo 1 > /proc/sys/kernel/hung_task_panic
```

## 5. **分析崩溃堆栈**

### **5.1 使用crash工具分析vmcore**
```bash
# 安装crash工具
sudo apt-get install crash
# 或
sudo yum install crash

# 分析vmcore
sudo crash /usr/lib/debug/lib/modules/$(uname -r)/vmlinux /var/crash/vmcore

# crash常用命令
crash> bt           # 查看当前任务堆栈
crash> bt -a        # 查看所有CPU堆栈
crash> ps           # 查看进程状态
crash> log          # 查看内核日志
crash> kmem -i      # 查看内存信息
crash> vm           # 查看虚拟内存
crash> sys          # 查看系统信息
crash> q            # 退出
```

### **5.2 使用GDB分析内核镜像**
```bash
# 需要调试信息的内核镜像
sudo apt-get install linux-image-$(uname -r)-dbg

# 使用GDB分析
gdb /usr/lib/debug/boot/vmlinux-$(uname -r)
(gdb) core-file /var/crash/vmcore
(gdb) bt
(gdb) info registers
(gdb) list *(函数地址)
```

### **5.3 自动分析脚本**
```bash
#!/bin/bash
# analyze_crash.sh - 自动分析崩溃堆栈

VMLINUX="/usr/lib/debug/lib/modules/$(uname -r)/vmlinux"
VMCORE="$1"

if [ ! -f "$VMLINUX" ]; then
    echo "调试内核不存在: $VMLINUX"
    exit 1
fi

if [ ! -f "$VMCORE" ]; then
    echo "vmcore文件不存在: $VMCORE"
    exit 1
fi

echo "=== 分析崩溃堆栈 ==="
echo "内核: $VMLINUX"
echo "Core文件: $VMCORE"
echo ""

# 使用crash分析
crash $VMLINUX $VMCORE << EOF
bt -a
ps
log | tail -50
q
EOF
```

## 6. **内核调试配置选项**

### **6.1 内核编译选项**
```bash
# 配置内核支持调试
make menuconfig

# 重要选项：
# Kernel hacking  --->
#   [*] Kernel debugging
#   [*] Compile the kernel with debug info
#   [*] Collect kernel timers statistics
#   [*] Collect scheduler statistics
#   [*] Debug memory allocations
#   [*] Spinlock and rw-lock debugging: basic checks
#   [*] Mutex debugging: basic checks
#   [*] Detect Hard and Soft Lockups
#   [*] Panic on Oops
```

### **6.2 运行时调试选项**
```bash
# 启用更多调试信息
echo 8 > /proc/sys/kernel/printk

# 启用slab调试
sudo modprobe slab_debug

# 启用kmemleak（内存泄漏检测）
echo scan=1 > /sys/kernel/debug/kmemleak

# 启用lockdep（锁依赖检测）
echo 1 > /proc/sys/kernel/lock_stat
```

## 7. **获取特定场景的堆栈**

### **7.1 获取软死锁堆栈**
```bash
# 配置hung task检测
echo 120 > /proc/sys/kernel/hung_task_timeout_secs
echo 1 > /proc/sys/kernel/hung_task_panic
echo 1 > /proc/sys/kernel/hung_task_check_count
echo 1 > /proc/sys/kernel/hung_task_warnings

# 查看当前hung tasks
cat /proc/sys/kernel/hung_task_timeout_secs
```

### **7.2 获取死锁堆栈**
```bash
# 启用lockdep
echo 1 > /proc/sys/kernel/lock_stat

# 查看锁依赖信息
cat /proc/lockdep_chains
cat /proc/lockdep

# 触发死锁检测（在模块中）
#include <linux/mutex.h>
static DEFINE_MUTEX(lock_a);
static DEFINE_MUTEX(lock_b);

// 错误的锁定顺序会导致死锁警告
mutex_lock(&lock_a);
mutex_lock(&lock_b);
// 在其他地方以相反顺序锁定会触发警告
```

### **7.3 获取内存错误堆栈**
```c
// 使用slub调试
sudo modprobe slub_debug=ZF

// 触发内存错误
#include <linux/slab.h>

char *buf = kmalloc(64, GFP_KERNEL);
memset(buf, 0xAA, 128);  // 缓冲区溢出
kfree(buf);
// 可能触发slub错误检测
```

## 8. **实际案例：调试驱动程序崩溃**

### **8.1 驱动程序触发Oops**
```c
// buggy_driver.c
#include <linux/module.h>
#include <linux/kernel.h>
#include <linux/fs.h>

static int major_num;

static int device_open(struct inode *inode, struct file *file)
{
    int *null_ptr = NULL;
    *null_ptr = 0xDEADBEEF;  // 空指针解引用
    return 0;
}

static struct file_operations fops = {
    .open = device_open,
};

static int __init driver_init(void)
{
    major_num = register_chrdev(0, "buggy_driver", &fops);
    printk(KERN_INFO "Buggy driver loaded with major %d\n", major_num);
    return 0;
}

static void __exit driver_exit(void)
{
    unregister_chrdev(major_num, "buggy_driver");
}

module_init(driver_init);
module_exit(driver_exit);
MODULE_LICENSE("GPL");
```

### **8.2 分析步骤**
```bash
# 1. 编译并加载模块
make
sudo insmod buggy_driver.ko

# 2. 触发崩溃
sudo cat /dev/buggy_driver  # 会触发Oops

# 3. 查看Oops信息
dmesg | tail -100

# 4. 使用addr2line解析地址
addr2line -e buggy_driver.ko -f -C 0x<PC地址>
# 或使用内核的scripts/decodecode工具
cat /proc/vmcore | scripts/decodecode
```

## 9. **自动化崩溃收集系统**

### **9.1 配置自动vmcore分析**
```bash
#!/bin/bash
# /etc/kdump-post.sh - kdump后处理脚本

VMCORE_PATH="$1"
HOSTNAME=$(hostname)
TIMESTAMP=$(date +%Y%m%d-%H%M%S)
REPORT_DIR="/var/crash/reports"

# 创建报告目录
mkdir -p $REPORT_DIR

# 生成基本报告
echo "=== 崩溃报告 $TIMESTAMP ===" > $REPORT_DIR/report-$TIMESTAMP.txt
echo "主机: $HOSTNAME" >> $REPORT_DIR/report-$TIMESTAMP.txt
echo "时间: $(date)" >> $REPORT_DIR/report-$TIMESTAMP.txt
echo "" >> $REPORT_DIR/report-$TIMESTAMP.txt

# 如果有crash工具，生成详细分析
if command -v crash &> /dev/null; then
    VMLINUX="/usr/lib/debug/lib/modules/$(uname -r)/vmlinux"
    if [ -f "$VMLINUX" ]; then
        crash $VMLINUX $VMCORE_PATH << EOF >> $REPORT_DIR/report-$TIMESTAMP.txt
bt -a
ps
log
sys
quit
EOF
    fi
fi

# 压缩vmcore节省空间
gzip $VMCORE_PATH
```

### **9.2 监控系统崩溃**
```bash
# 监控panic事件
journalctl -k -f | grep -i "panic\|oops\|segfault"

# 监控系统稳定性
#!/bin/bash
while true; do
    if dmesg | tail -20 | grep -q "Oops\|panic"; then
        echo "检测到内核崩溃: $(date)"
        # 发送警报
        # mail -s "内核崩溃警报" admin@example.com
    fi
    sleep 10
done
```

## 10. **最佳实践与注意事项**

### **生产环境建议：**
```bash
# 1. 保留足够的崩溃内存
# 一般规则：物理内存的10-15%，至少128M
crashkernel=512M

# 2. 定期测试kdump
echo 1 > /proc/sys/kernel/sysrq
echo c > /proc/sysrq-trigger

# 3. 配置自动清理旧vmcore
find /var/crash -name "vmcore*" -mtime +7 -delete
find /var/crash -name "report*" -mtime +30 -delete

# 4. 确保有足够磁盘空间
# vmcore大小 ≈ 物理内存大小
```

### **调试技巧：**
1. **保存完整的dmesg**：崩溃前的日志很重要
2. **多次崩溃对比**：同一问题的多次崩溃堆栈可能有差异
3. **符号信息**：确保有正确的调试符号文件
4. **硬件信息**：记录CPU、内存、主板等硬件信息
5. **复现步骤**：详细记录如何复现崩溃

### **常见问题解决：**
```bash
# kdump服务无法启动
sudo systemctl restart kdump
sudo dmesg | grep -i kdump

# 没有生成vmcore
# 检查：内存保留、磁盘空间、权限、服务状态

# crash工具无法解析
# 确保vmlinux版本与崩溃内核完全一致
uname -r
ls /usr/lib/debug/lib/modules/
```

## 总结
生成和分析内核崩溃堆栈需要：
1. **配置kdump**：保留内存，安装工具
2. **触发崩溃**：通过模块、sysrq或故意错误
3. **收集信息**：vmcore、dmesg、系统状态
4. **分析堆栈**：使用crash、gdb等工具
5. **定位问题**：结合代码和堆栈信息

合理配置崩溃收集系统，可以大大加速内核问题的诊断和修复过程。